# full_site_analyzer.py
import asyncio
import aiohttp
import json
import sys
import re
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
import argparse
import logging
from urllib.parse import urljoin

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class MobilePlan:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ç–∞—Ä–∏—Ñ–∞"""
    name: str
    operator: str
    price: str
    data: str
    calls: str = ""
    sms: str = ""
    validity: str = ""
    additional_info: str = ""
    source_url: str = ""
    
class SiteStructureAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–æ–≤ –Ω–æ—Ä–≤–µ–∂—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤"""
    
    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
        self.plans: List[MobilePlan] = []
        
        # URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.test_urls = {
            'mobilabonnement.no': 'https://www.mobilabonnement.no',
            'telia': 'https://www.telia.no/privat/mobil/abonnement',
            'telenor': 'https://www.telenor.no/privat/mobil/abonnement',
            'ice': 'https://www.ice.no/mobil/abonnement',
            'mycall': 'https://mycall.no'
        }
        
        # Cookie –±–∞–Ω–Ω–µ—Ä—ã - —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
        self.cookie_selectors = {
            'accept_buttons': [
                '[data-testid*="accept"]', '[data-cy*="accept"]',
                '.cookie-accept', '.accept-cookies', '.gdpr-accept',
                'button[class*="accept"]', 'button[id*="accept"]',
                'button:-soup-contains("Godta")', 'button:-soup-contains("Accept")',
                'button:-soup-contains("Aksepter")', 'button:-soup-contains("OK")',
                '[aria-label*="accept"]', '[title*="accept"]'
            ],
            'close_buttons': [
                '.cookie-close', '.modal-close', '.banner-close',
                'button[aria-label*="close"]', 'button[title*="close"]',
                '.close', '[data-dismiss]', '.dismiss'
            ],
            'banner_containers': [
                '.cookie-banner', '.gdpr-banner', '.consent-banner',
                '.privacy-notice', '#cookie-notice', '#gdpr-notice',
                '[class*="cookie"]', '[class*="consent"]', '[class*="gdpr"]',
                '[id*="cookie"]', '[id*="consent"]', '[role="dialog"]'
            ]
        }
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5,no;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none'
        }

    async def __aenter__(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç-–º–µ–Ω–µ–¥–∂–µ—Ä"""
        connector = aiohttp.TCPConnector(limit=10, limit_per_host=5, ttl_dns_cache=300, ssl=False)
        timeout = aiohttp.ClientTimeout(total=30, connect=10)
        self.session = aiohttp.ClientSession(
            headers=self.headers,
            connector=connector,
            timeout=timeout,
            cookie_jar=aiohttp.CookieJar(unsafe=True)
        )
        return self

    async def detect_cookie_banner(self, soup: BeautifulSoup, page_text: str) -> Dict[str, Any]:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ cookie –±–∞–Ω–Ω–µ—Ä–∞"""
        cookie_info = {
            'detected': False,
            'banner_elements': [],
            'accept_buttons': [],
            'close_buttons': [],
            'text_indicators': [],
            'banner_text': '',
            'position': 'unknown',
            'modal_overlay': False
        }
        
        # –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        cookie_keywords = {
            'norwegian': ['informasjonskapsler', 'samtykke', 'personvern', 'cookies', 'godta'],
            'english': ['cookies', 'consent', 'privacy', 'accept', 'gdpr', 'tracking'],
            'common': ['cookie', 'gdpr', 'privacy policy', 'data protection']
        }
        
        found_keywords = []
        for lang, keywords in cookie_keywords.items():
            for keyword in keywords:
                if keyword.lower() in page_text:
                    found_keywords.append(f"{keyword} ({lang})")
        
        cookie_info['text_indicators'] = found_keywords
        
        # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –±–∞–Ω–Ω–µ—Ä–æ–≤
        for selector in self.cookie_selectors['banner_containers']:
            try:
                elements = soup.select(selector)
                if elements:
                    for elem in elements:
                        text = elem.get_text().strip()[:200]
                        if any(kw in text.lower() for kw_list in cookie_keywords.values() for kw in kw_list):
                            cookie_info['banner_elements'].append({
                                'selector': selector,
                                'text': text,
                                'classes': elem.get('class', []),
                                'id': elem.get('id', ''),
                                'position': self._detect_banner_position(elem)
                            })
            except Exception:
                continue
        
        # –ü–æ–∏—Å–∫ –∫–Ω–æ–ø–æ–∫ –ø—Ä–∏–Ω—è—Ç–∏—è
        for selector in self.cookie_selectors['accept_buttons']:
            try:
                elements = soup.select(selector)
                for elem in elements:
                    text = elem.get_text().strip()
                    if text and any(word in text.lower() for word in ['godta', 'accept', 'ok', 'aksepter']):
                        cookie_info['accept_buttons'].append({
                            'selector': selector,
                            'text': text,
                            'element_type': elem.name,
                            'classes': elem.get('class', []),
                            'id': elem.get('id', '')
                        })
            except Exception:
                continue
        
        # –ü–æ–∏—Å–∫ –∫–Ω–æ–ø–æ–∫ –∑–∞–∫—Ä—ã—Ç–∏—è
        for selector in self.cookie_selectors['close_buttons']:
            try:
                elements = soup.select(selector)
                if elements:
                    for elem in elements:
                        cookie_info['close_buttons'].append({
                            'selector': selector,
                            'element_type': elem.name,
                            'classes': elem.get('class', []),
                            'id': elem.get('id', '')
                        })
            except Exception:
                continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
        modal_indicators = soup.select('[role="dialog"], .modal, .overlay, [class*="modal"], [class*="overlay"]')
        cookie_info['modal_overlay'] = len(modal_indicators) > 0
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è –±–∞–Ω–Ω–µ—Ä–∞
        cookie_info['detected'] = (
            len(found_keywords) >= 2 or 
            len(cookie_info['banner_elements']) > 0 or 
            len(cookie_info['accept_buttons']) > 0
        )
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –±–∞–Ω–Ω–µ—Ä–∞
        if cookie_info['banner_elements']:
            cookie_info['banner_text'] = cookie_info['banner_elements'][0]['text']
            cookie_info['position'] = cookie_info['banner_elements'][0]['position']
        
        return cookie_info
    
    def _detect_banner_position(self, element) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –±–∞–Ω–Ω–µ—Ä–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        classes = ' '.join(element.get('class', [])).lower()
        style = element.get('style', '').lower()
        
        position_indicators = {
            'top': ['top', 'header', 'fixed-top'],
            'bottom': ['bottom', 'footer', 'fixed-bottom'],
            'center': ['center', 'modal', 'popup'],
            'overlay': ['overlay', 'fixed', 'absolute']
        }
        
        for position, indicators in position_indicators.items():
            if any(indicator in classes or indicator in style for indicator in indicators):
                return position
        
        return 'unknown'
    
    async def handle_cookie_consent(self, soup: BeautifulSoup, cookie_info: Dict[str, Any]) -> bool:
        """–≠–º—É–ª—è—Ü–∏—è –ø—Ä–∏–Ω—è—Ç–∏—è cookie —Å–æ–≥–ª–∞—Å–∏—è"""
        if not cookie_info['detected']:
            return False
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è cookie
        logger.info("üç™ Cookie –±–∞–Ω–Ω–µ—Ä –æ–±–Ω–∞—Ä—É–∂–µ–Ω:")
        
        if cookie_info['accept_buttons']:
            logger.info(f"   –ù–∞–π–¥–µ–Ω–æ {len(cookie_info['accept_buttons'])} –∫–Ω–æ–ø–æ–∫ –ø—Ä–∏–Ω—è—Ç–∏—è:")
            for btn in cookie_info['accept_buttons'][:3]:
                logger.info(f"     ‚Ä¢ {btn['selector']}: '{btn['text']}'")
        
        if cookie_info['banner_elements']:
            logger.info(f"   –ù–∞–π–¥–µ–Ω–æ {len(cookie_info['banner_elements'])} –±–∞–Ω–Ω–µ—Ä–æ–≤:")
            for banner in cookie_info['banner_elements'][:2]:
                logger.info(f"     ‚Ä¢ {banner['selector']}: {banner['text'][:50]}...")
        
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã –±—ã–ª –∫–æ–¥ –¥–ª—è –∫–ª–∏–∫–∞ –ø–æ –∫–Ω–æ–ø–∫–µ
        # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º—ã –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, —á—Ç–æ –º–æ–∂–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
        return len(cookie_info['accept_buttons']) > 0

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏"""
        if self.session:
            await self.session.close()

    def _clean_text(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if not text:
            return ""
        return re.sub(r'\s+', ' ', text.strip())

    def _extract_price(self, text: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return ""
        
        # –ü–æ–∏—Å–∫ –Ω–æ—Ä–≤–µ–∂—Å–∫–∏—Ö –∫—Ä–æ–Ω (NOK, kr)
        price_patterns = [
            r'(\d+(?:,\d+)?)\s*kr',
            r'(\d+(?:,\d+)?)\s*NOK',
            r'kr\s*(\d+(?:,\d+)?)',
            r'NOK\s*(\d+(?:,\d+)?)',
            r'(\d+(?:,\d+)?)\s*,-'
        ]
        
        for pattern in price_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return f"{match.group(1)} kr"
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        return self._clean_text(text)

    def _extract_data_amount(self, text: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return ""
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        data_patterns = [
            r'(\d+(?:,\d+)?)\s*GB',
            r'(\d+(?:,\d+)?)\s*TB',
            r'(\d+(?:,\d+)?)\s*MB',
            r'ubegrenset|unlimited|fri\s*data',
            r'(\d+)\s*giga'
        ]
        
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–µ–∑–ª–∏–º–∏—Ç
        if any(word in text_lower for word in ['ubegrenset', 'unlimited', 'fri data', 'uten grense']):
            return "Unlimited"
        
        for pattern in data_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                if pattern.endswith('giga'):
                    return f"{match.group(1)} GB"
                return match.group(0)
        
        return self._clean_text(text)

    async def analyze_page(self, name: str, url: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        analysis = {
            'name': name,
            'url': url,
            'status': 'error',
            'response_code': None,
            'content_length': 0,
            'title': '',
            'has_cookie_banner': False,
            'cookie_details': {},
            'cookie_handled': False,
            'requires_js': False,
            'common_selectors': {},
            'potential_plan_containers': [],
            'text_content_sample': '',
            'meta_info': {}
        }
        
        try:
            logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ {name}: {url}")
            async with self.session.get(url, allow_redirects=True) as response:
                analysis['response_code'] = response.status
                analysis['final_url'] = str(response.url)
                
                if response.status != 200:
                    analysis['status'] = f'HTTP {response.status}'
                    return analysis
                
                html = await response.text()
                analysis['content_length'] = len(html)
                
                # –ü–∞—Ä—Å–∏–Ω–≥ HTML
                soup = BeautifulSoup(html, 'html.parser')
                
                # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                title_tag = soup.find('title')
                analysis['title'] = title_tag.get_text().strip() if title_tag else '–ù–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞'
                
                # –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ cookie –±–∞–Ω–Ω–µ—Ä–∞
                cookie_indicators = [
                    'cookie', 'gdpr', 'privacy', 'consent', 'samtykke', 
                    'informasjonskapsler', 'personvern'
                ]
                page_text = html.lower()
                cookie_info = await self.detect_cookie_banner(soup, page_text)
                # –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Å –ø–æ–º–æ—â—å—é –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                if cookie_info['detected']:
                    analysis['has_cookie_banner'] = True
                else:
                    # –ï—Å–ª–∏ –Ω–µ –±—ã–ª–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    analysis['has_cookie_banner'] = any(word in page_text for word in cookie_indicators)

                analysis['cookie_details'] = cookie_info
                
                # –ü–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ cookie —Å–æ–≥–ª–∞—Å–∏—è
                if cookie_info['detected']:
                    analysis['cookie_handled'] = await self.handle_cookie_consent(soup, cookie_info)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å JavaScript
                js_indicators = [
                    'document.getElementById', 'addEventListener', 'React', 'Vue', 'Angular',
                    'loading...', 'Laster...', 'javascript', 'noscript'
                ]
                analysis['requires_js'] = any(indicator.lower() in page_text for indicator in js_indicators)
                
                # –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –ø–ª–∞–Ω–æ–≤
                plan_containers = []
                
                # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–∞—Ä—Ç–æ—á–µ–∫ –ø–ª–∞–Ω–æ–≤
                container_selectors = [
                    '.plan', '.product', '.card', '.subscription', '.abonnement',
                    '.offer', '.package', '.tariff', '.mobile-plan',
                    '[class*="plan"]', '[class*="product"]', '[class*="card"]',
                    '[class*="subscription"]', '[id*="plan"]'
                ]
                
                for selector in container_selectors:
                    try:
                        elements = soup.select(selector)
                        if elements:
                            plan_containers.append({
                                'selector': selector,
                                'count': len(elements),
                                'sample_text': elements[0].get_text()[:100] if elements else ''
                            })
                    except:
                        continue
                
                analysis['potential_plan_containers'] = plan_containers
                
                # –ê–Ω–∞–ª–∏–∑ –æ–±—â–∏—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
                common_selectors = {
                    'h1': len(soup.select('h1')),
                    'h2': len(soup.select('h2')),
                    'h3': len(soup.select('h3')),
                    '.price': len(soup.select('.price')),
                    '.kr': len(soup.select('.kr')),
                    '[class*="price"]': len(soup.select('[class*="price"]')),
                    '[class*="kr"]': len(soup.select('[class*="kr"]')),
                    '.btn, .button': len(soup.select('.btn, .button')),
                    'form': len(soup.select('form')),
                    'table': len(soup.select('table'))
                }
                analysis['common_selectors'] = {k: v for k, v in common_selectors.items() if v > 0}
                
                # –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                meta_tags = {}
                for meta in soup.find_all('meta'):
                    name = meta.get('name') or meta.get('property', '')
                    content = meta.get('content', '')
                    if name and content:
                        meta_tags[name] = content[:100]
                analysis['meta_info'] = meta_tags
                
                # –û–±—Ä–∞–∑–µ—Ü —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                body = soup.find('body')
                if body:
                    text_content = body.get_text()
                    # –û—á–∏—Å—Ç–∫–∞ –∏ –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤
                    clean_text = ' '.join(text_content.split())
                    analysis['text_content_sample'] = clean_text[:500] + '...' if len(clean_text) > 500 else clean_text
                
                analysis['status'] = 'success'
                logger.info(f"‚úÖ {name}: –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω ({analysis['content_length']} —Å–∏–º–≤–æ–ª–æ–≤)")
                
        except asyncio.TimeoutError:
            analysis['status'] = 'timeout'
            logger.warning(f"‚è±Ô∏è {name}: –¢–∞–π–º–∞—É—Ç")
        except Exception as e:
            analysis['status'] = f'error: {str(e)}'
            logger.error(f"‚ùå {name}: {e}")
            
        return analysis

    async def analyze_all_sites(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤"""
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–æ–≤")
        
        tasks = []
        for name, url in self.test_urls.items():
            task = self.analyze_page(name, url)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        analysis_results = {}
        for i, result in enumerate(results):
            name = list(self.test_urls.keys())[i]
            if isinstance(result, Exception):
                analysis_results[name] = {
                    'name': name,
                    'status': f'exception: {str(result)}',
                    'url': self.test_urls[name]
                }
            else:
                analysis_results[name] = result
        
        return analysis_results

    def print_analysis_report(self, results: Dict[str, Any]):
        """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        print("\n" + "="*80)
        print("üìä –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –°–¢–†–£–ö–¢–£–†–´ –°–ê–ô–¢–û–í")
        print("="*80)
        
        for name, analysis in results.items():
            print(f"\nüåê {analysis['name'].upper()}")
            print(f"   URL: {analysis['url']}")
            print(f"   –°—Ç–∞—Ç—É—Å: {analysis['status']}")
            
            if analysis['status'] == 'success':
                print(f"   HTTP –∫–æ–¥: {analysis['response_code']}")
                print(f"   –†–∞–∑–º–µ—Ä: {analysis['content_length']:,} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫: {analysis['title']}")
                print(f"   Cookie –±–∞–Ω–Ω–µ—Ä: {'–î–∞' if analysis['has_cookie_banner'] else '–ù–µ—Ç'}")
                
                # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ cookie
                if analysis['has_cookie_banner'] and analysis.get('cookie_details'):
                    cookie_details = analysis['cookie_details']
                    print(f"   üç™ Cookie –¥–µ—Ç–∞–ª–∏:")
                    print(f"      ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω: {'–î–∞' if analysis.get('cookie_handled') else '–ù–µ—Ç'}")
                    print(f"      ‚Ä¢ –ü–æ–∑–∏—Ü–∏—è: {cookie_details.get('position', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
                    print(f"      ‚Ä¢ –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ: {'–î–∞' if cookie_details.get('modal_overlay') else '–ù–µ—Ç'}")
                    
                    if cookie_details.get('accept_buttons'):
                        print(f"      ‚Ä¢ –ö–Ω–æ–ø–∫–∏ –ø—Ä–∏–Ω—è—Ç–∏—è: {len(cookie_details['accept_buttons'])}")
                        for btn in cookie_details['accept_buttons'][:2]:
                            print(f"        - '{btn['text']}' ({btn['selector']})")
                    
                    if cookie_details.get('text_indicators'):
                        indicators = ', '.join(cookie_details['text_indicators'][:3])
                        print(f"      ‚Ä¢ –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {indicators}")
                
                print(f"   –¢—Ä–µ–±—É–µ—Ç JS: {'–î–∞' if analysis['requires_js'] else '–ù–µ—Ç'}")
                
                if analysis['potential_plan_containers']:
                    print(f"   üì¶ –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –ø–ª–∞–Ω–æ–≤:")
                    for container in analysis['potential_plan_containers'][:5]:
                        print(f"      ‚Ä¢ {container['selector']}: {container['count']} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                        if container['sample_text'].strip():
                            sample = container['sample_text'].strip()[:60]
                            print(f"        –ü—Ä–∏–º–µ—Ä: {sample}{'...' if len(sample) == 60 else ''}")
                else:
                    print(f"   üì¶ –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –ø–ª–∞–Ω–æ–≤: –ù–µ –Ω–∞–π–¥–µ–Ω—ã")
                
                if analysis['common_selectors']:
                    print(f"   üéØ –ü–æ–ª–µ–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã:")
                    for selector, count in list(analysis['common_selectors'].items())[:5]:
                        print(f"      ‚Ä¢ {selector}: {count}")
                
                # –û–±—Ä–∞–∑–µ—Ü –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                if analysis['text_content_sample']:
                    print(f"   üìù –û–±—Ä–∞–∑–µ—Ü –∫–æ–Ω—Ç–µ–Ω—Ç–∞:")
                    sample_lines = analysis['text_content_sample'][:200].split('\n')[:3]
                    for line in sample_lines:
                        if line.strip():
                            print(f"      {line.strip()[:70]}...")
            
            print("-" * 60)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        self.print_recommendations(results)

    def print_recommendations(self, results: Dict[str, Any]):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        print("\n" + "üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ü–ê–†–°–ò–ù–ì–£")
        print("="*60)
        
        successful_sites = [r for r in results.values() if r['status'] == 'success']
        
        if not successful_sites:
            print("‚ùå –ù–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–∞–π—Ç–æ–≤ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
            return
        
        # –ê–Ω–∞–ª–∏–∑ –æ–±—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        print("\nüìã –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞:")
        
        # Cookie –±–∞–Ω–Ω–µ—Ä—ã - –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        cookie_sites = [s for s in successful_sites if s.get('has_cookie_banner')]
        if cookie_sites:
            print(f"\nüç™ Cookie –±–∞–Ω–Ω–µ—Ä—ã –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ {len(cookie_sites)} —Å–∞–π—Ç–∞—Ö:")
            for site in cookie_sites:
                cookie_details = site.get('cookie_details', {})
                handled = "‚úÖ" if site.get('cookie_handled') else "‚ùå"
                position = cookie_details.get('position', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                modal = "–º–æ–¥–∞–ª—å–Ω–æ–µ" if cookie_details.get('modal_overlay') else "–±–∞–Ω–Ω–µ—Ä"
                
                print(f"   ‚Ä¢ {site['name']} {handled} - {position} ({modal})")
                
                # –ü–æ–∫–∞–∑–∞—Ç—å –ª—É—á—à–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
                accept_buttons = cookie_details.get('accept_buttons', [])
                if accept_buttons:
                    best_button = accept_buttons[0]  # –ü–µ—Ä–≤—ã–π –æ–±—ã—á–Ω–æ –ª—É—á—à–∏–π
                    print(f"     –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä: {best_button['selector']}")
                    print(f"     –¢–µ–∫—Å—Ç –∫–Ω–æ–ø–∫–∏: '{best_button['text']}'")
            
            print("   üìã –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            print("     1. Selenium/Playwright –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–ª–∏–∫–∞")
            print("     2. –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ cookie –¥–ª—è –æ–±—Ö–æ–¥–∞")
            print("     3. –≠–º—É–ª—è—Ü–∏—è —Å–æ–≥–ª–∞—Å–∏—è —á–µ—Ä–µ–∑ HTTP –∑–∞–≥–æ–ª–æ–≤–∫–∏")
        else:
            print("\nüç™ Cookie –±–∞–Ω–Ω–µ—Ä—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
        
        # JavaScript –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        js_sites = [s for s in successful_sites if s.get('requires_js')]
        if js_sites:
            print(f"\n‚ö° JavaScript —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞ {len(js_sites)} —Å–∞–π—Ç–∞—Ö:")
            for site in js_sites:
                print(f"   ‚Ä¢ {site['name']}")
            print("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Selenium –∏–ª–∏ Playwright –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞")
        
        # –û–±—â–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
        all_selectors = {}
        for site in successful_sites:
            for selector, count in site.get('common_selectors', {}).items():
                if selector not in all_selectors:
                    all_selectors[selector] = []
                all_selectors[selector].append((site['name'], count))
        
        print(f"\nüéØ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã:")
        for selector, site_counts in sorted(all_selectors.items(), 
                                          key=lambda x: len(x[1]), reverse=True):
            if len(site_counts) >= 2:  # –°–µ–ª–µ–∫—Ç–æ—Ä –µ—Å—Ç—å –º–∏–Ω–∏–º—É–º –Ω–∞ 2 —Å–∞–π—Ç–∞—Ö
                sites_str = ', '.join([f"{name}({count})" for name, count in site_counts[:3]])
                print(f"   ‚Ä¢ {selector}: {sites_str}")
        
        # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –ø–ª–∞–Ω–æ–≤
        print(f"\nüì¶ –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –ø–ª–∞–Ω–æ–≤:")
        for site in successful_sites:
            containers = site.get('potential_plan_containers', [])
            if containers:
                print(f"\n   üåê {site['name'].upper()}:")
                for container in containers[:3]:
                    print(f"      ‚úì {container['selector']} ({container['count']} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
            else:
                print(f"   ‚ùå {site['name']}: –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print(f"\nüí° –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ —Å—Ç—Ä–∞–Ω–∏—Ü
        large_pages = [s for s in successful_sites if s.get('content_length', 0) > 500000]
        if large_pages:
            print(f"   üìÑ –ë–æ–ª—å—à–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (>500KB):")
            for site in large_pages:
                size_kb = site['content_length'] // 1024
                print(f"      ‚Ä¢ {site['name']}: {size_kb}KB - –≤–æ–∑–º–æ–∂–Ω–∞ –º–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞")
        
        # –ê–Ω–∞–ª–∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        title_patterns = {}
        for site in successful_sites:
            title = site.get('title', '').lower()
            words = [w for w in title.split() if len(w) > 3]
            for word in words[:3]:  # –ü–µ—Ä–≤—ã–µ 3 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤–∞
                if word not in title_patterns:
                    title_patterns[word] = []
                title_patterns[word].append(site['name'])
        
        common_title_words = {k: v for k, v in title_patterns.items() if len(v) >= 2}
        if common_title_words:
            print(f"   üî§ –û–±—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö:")
            for word, sites in sorted(common_title_words.items(), 
                                    key=lambda x: len(x[1]), reverse=True):
                sites_str = ', '.join(sites)
                print(f"      ‚Ä¢ '{word}': {sites_str}")

    def generate_cookie_automation_code(self, results: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ cookie"""
        successful_sites = [r for r in results.values() if r['status'] == 'success']
        cookie_sites = [s for s in successful_sites if s.get('has_cookie_banner')]
        
        if not cookie_sites:
            return "# Cookie –±–∞–Ω–Ω–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        code_lines = [
            "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ cookie —Å–æ–≥–ª–∞—Å–∏–π",
            "from selenium import webdriver",
            "from selenium.webdriver.common.by import By",
            "from selenium.webdriver.support.ui import WebDriverWait",
            "from selenium.webdriver.support import expected_conditions as EC",
            "import time",
            "",
            "def handle_cookie_consent(driver, site_name):",
            "    \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ cookie —Å–æ–≥–ª–∞—Å–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∞–π—Ç–∞\"\"\"",
            "    cookie_selectors = {"
        ]
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∞–π—Ç–∞
        for site in cookie_sites:
            cookie_details = site.get('cookie_details', {})
            accept_buttons = cookie_details.get('accept_buttons', [])
            
            if accept_buttons:
                site_name = site['name'].replace('.', '_').replace('-', '_')
                selectors = [btn['selector'] for btn in accept_buttons[:3]]
                code_lines.append(f"        '{site_name}': {selectors},")
        
        code_lines.extend([
            "    }",
            "",
            "    if site_name not in cookie_selectors:",
            "        return False",
            "",
            "    for selector in cookie_selectors[site_name]:",
            "        try:",
            "            # –û–∂–∏–¥–∞–Ω–∏–µ –ø–æ—è–≤–ª–µ–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞",
            "            element = WebDriverWait(driver, 5).until(",
            "                EC.element_to_be_clickable((By.CSS_SELECTOR, selector))",
            "            )",
            "            element.click()",
            "            print(f'‚úÖ Cookie —Å–æ–≥–ª–∞—Å–∏–µ –ø—Ä–∏–Ω—è—Ç–æ: {selector}')",
            "            time.sleep(1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞",
            "            return True",
            "        except Exception as e:",
            "            continue",
            "",
            "    print(f'‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å cookie –¥–ª—è {site_name}')",
            "    return False",
            "",
            "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:",
            "# driver = webdriver.Chrome()",
            "# driver.get('https://example.com')",
            "# handle_cookie_consent(driver, 'example_site')"
        ])
        
        return '\n'.join(code_lines)
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

    def export_results(self, results: Dict[str, Any], filename: str = 'site_analysis.json'):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
    
    def add_custom_url(self, name: str, url: str):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        self.test_urls[name] = url
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω URL: {name} -> {url}")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–æ–≤')
    parser.add_argument('--export', '-e', help='–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON —Ñ–∞–π–ª')
    parser.add_argument('--export-cookies', help='–≠–∫—Å–ø–æ—Ä—Ç –∫–æ–¥–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ cookie')
    parser.add_argument('--url', nargs=2, metavar=('NAME', 'URL'), 
                       help='–î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π URL: --url mysite https://example.com')
    parser.add_argument('--silent', '-s', action='store_true', 
                       help='–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥')
    args = parser.parse_args()
    
    if args.silent:
        logging.getLogger().setLevel(logging.WARNING)
    
    async with SiteStructureAnalyzer() as analyzer:
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ URL
        if args.url:
            analyzer.add_custom_url(args.url[0], args.url[1])
        
        # –ê–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–æ–≤
        results = await analyzer.analyze_all_sites()
        
        # –í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞
        if not args.silent:
            analyzer.print_analysis_report(results)
        
        # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if args.export:
            analyzer.export_results(results, args.export)
        
        # –≠–∫—Å–ø–æ—Ä—Ç –∫–æ–¥–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ cookie
        if args.export_cookies:
            analyzer.export_cookie_automation(results, args.export_cookies)
        
        # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        successful = len([r for r in results.values() if r['status'] == 'success'])
        total = len(results)
        print(f"\nüéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {successful}/{total} —Å–∞–π—Ç–æ–≤ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –ê–Ω–∞–ª–∏–∑ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)